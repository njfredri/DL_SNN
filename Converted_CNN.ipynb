{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# spikingjelly.activation_based.examples.conv_fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from torch.cuda import amp\n",
    "import sys\n",
    "import datetime\n",
    "from spikingjelly import visualizing\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model needs to account for 2 things:\n",
    "\n",
    "1. ANN proposes Batch Normalization for fast training and convergence. Batch normalization aims to normalize the ANN output to 0 mean, which is contrary to the properties of SNNs. Therefore, the parameters of BN can be absorbed into the previous parameter layers (Linear, Conv2d)\n",
    "\n",
    "2. According to the transformation theory, the input and output of each layer of ANN need to be limited to the range of [0,1], which requires scaling the parameters (model normalization)\n",
    "\n",
    "3. There is not a good way to use MaxPooling. AvgPool is recommended instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_Modified(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet_Modified, self).__init__()\n",
    "        #5x5 kernal on 28x28 image. Should have 2 padding for \"32x32\" image\n",
    "        self.c1 = nn.Conv2d(in_channels=1, kernel_size=5, padding=2, out_channels=6) #results in 28x28 in 6 channels. Should have 1 channel-in bc it is one image at first\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=6, eps=1e-3)\n",
    "        self.ap1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        #Relu 28x28 -> 28x28\n",
    "        #avg pool 28x28 -> 14x14 (stride=2)\n",
    "        self.c2 = nn.Conv2d(in_channels=6, kernel_size=5, out_channels=16) #6 channels to 16 channels. 14x14 -> 10x10 with 5x5kernel\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=16, eps=1e-3)\n",
    "        self.ap2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        #avg pool 10x10 -> 5x5\n",
    "        self.fc1 = nn.Linear(25*16, 120) #5x5 images, 16 channels in. 120 out\n",
    "        self.fc2 = nn.Linear(120, 84) #120 -> 84\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            self.c1,\n",
    "            self.bn1,\n",
    "            nn.ReLU(),\n",
    "            self.ap1,\n",
    "            self.c2,\n",
    "            self.bn2,\n",
    "            nn.ReLU(),\n",
    "            self.ap2,\n",
    "            nn.Flatten(),\n",
    "            self.fc1,\n",
    "            nn.ReLU(),\n",
    "            self.fc2,\n",
    "            nn.ReLU(),\n",
    "            self.fc3,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "\n",
    "    def name(self):\n",
    "        return \"LeNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=100\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "model_ann = LeNet_Modified().to(device=device)\n",
    "optimizer = torch.optim.Adam(model_ann.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the FMNIST dataset and then create the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:26<00:00, 1010507.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./FMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 232737.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./FMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:02<00:00, 1603047.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./FMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./FMNIST\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root = './FMNIST'\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    # trainning\n",
    "    total_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, target = x.cuda(), target.cuda()\n",
    "        out = model_ann(x)\n",
    "        loss = criterion(out, target)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = total_loss / len(train_set)\n",
    "    print(f'==>>> epoch: {epoch}, train loss: {avg_loss:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
