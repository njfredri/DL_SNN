{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# spikingjelly.activation_based.examples.conv_fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from spikingjelly.activation_based import encoding, monitor\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from spikingjelly.activation_based import lava_exchange\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from torch.cuda import amp\n",
    "import sys\n",
    "import datetime\n",
    "from spikingjelly import visualizing\n",
    "import numpy as np\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCNN(nn.Module):\n",
    "    def __init__(self, T: int):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv_and_fc = nn.Sequential(\n",
    "            layer.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2, bias=False),\n",
    "            layer.BatchNorm2d(6),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            layer.Conv2d(in_channels=6, out_channels=12, kernel_size=5, bias=False),\n",
    "            layer.BatchNorm2d(12),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            layer.Flatten(),\n",
    "            layer.Linear(5*5*12, 10, bias=False),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            # layer.Linear(120, 84),\n",
    "            # neuron.IFNode(surrogate_function=surrogate.LeakyKReLU()),\n",
    "            # layer.Linear(84, 10),\n",
    "            # neuron.IFNode(surrogate_function=surrogate.ATan())\n",
    "            )\n",
    "        functional.set_step_mode(self, step_mode='m')\n",
    "    def forward(self, x):\n",
    "        x_seq = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1)\n",
    "        z = self.conv_and_fc(x_seq)\n",
    "        fr = z.mean(0)\n",
    "        return fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = 2.0\n",
    "timesteps = 5\n",
    "model = SCNN(T=timesteps).to(device=device)\n",
    "EPOCHS=50 #set to 50 epochs bc of diminishing returns\n",
    "AMP=True #automatic mixed precision training\n",
    "lr= 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "out_dir = \"./outputs/CSNN\"\n",
    "encoder = encoding.PoissonEncoder()\n",
    "batch_size=64\n",
    "num_workers = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './FMNIST'\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=train_set,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=test_set,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the CSNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = None\n",
    "if AMP:\n",
    "    scaler = amp.GradScaler()\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    print(f'Mkdir {out_dir}.')\n",
    "\n",
    "writer = SummaryWriter(out_dir, purge_step=0)\n",
    "with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "    args_txt.write('\\n')\n",
    "    args_txt.write(' '.join(sys.argv))\n",
    "file_dir = './Models/'\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)\n",
    "    print(f'Mkdir {file_dir}.')\n",
    "full_path = file_dir + '/CSNN.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best model saved\n",
      "epoch: 0; loss2017.6280869841576\n",
      "new best model saved\n",
      "epoch: 1; loss1433.516050875187\n",
      "new best model saved\n",
      "epoch: 2; loss1313.0240403413773\n",
      "new best model saved\n",
      "epoch: 3; loss1263.2720425128937\n",
      "new best model saved\n",
      "epoch: 4; loss1219.2120375037193\n",
      "new best model saved\n",
      "epoch: 5; loss1196.2160358428955\n",
      "new best model saved\n",
      "epoch: 6; loss1179.8680365979671\n",
      "new best model saved\n",
      "epoch: 7; loss1160.8400334715843\n",
      "new best model saved\n",
      "epoch: 8; loss1150.8440335094929\n",
      "new best model saved\n",
      "epoch: 9; loss1137.6760341525078\n",
      "new best model saved\n",
      "epoch: 10; loss1132.9720305204391\n",
      "new best model saved\n",
      "epoch: 11; loss1112.9480350017548\n",
      "new best model saved\n",
      "epoch: 12; loss1107.524032086134\n",
      "new best model saved\n",
      "epoch: 13; loss1100.2840290367603\n",
      "new best model saved\n",
      "epoch: 14; loss1094.192030787468\n",
      "new best model saved\n",
      "epoch: 15; loss1087.76003241539\n",
      "new best model saved\n",
      "epoch: 16; loss1086.1320283710957\n",
      "new best model saved\n",
      "epoch: 17; loss1079.8360337615013\n",
      "new best model saved\n",
      "epoch: 18; loss1069.0400296747684\n",
      "epoch: 19; loss1069.9240321218967\n",
      "new best model saved\n",
      "epoch: 20; loss1061.1000327467918\n",
      "epoch: 21; loss1064.1400321424007\n",
      "new best model saved\n",
      "epoch: 22; loss1053.296028316021\n",
      "new best model saved\n",
      "epoch: 23; loss1052.9000302255154\n",
      "new best model saved\n",
      "epoch: 24; loss1050.0440307855606\n",
      "epoch: 25; loss1051.0400304198265\n",
      "new best model saved\n",
      "epoch: 26; loss1044.9240327775478\n",
      "new best model saved\n",
      "epoch: 27; loss1038.1480286717415\n",
      "epoch: 28; loss1039.9560284912586\n",
      "new best model saved\n",
      "epoch: 29; loss1032.8320322036743\n",
      "new best model saved\n",
      "epoch: 30; loss1028.8720320761204\n",
      "epoch: 31; loss1031.0960267335176\n",
      "new best model saved\n",
      "epoch: 32; loss1023.4840306043625\n",
      "new best model saved\n",
      "epoch: 33; loss1020.9440292716026\n",
      "epoch: 34; loss1023.5360320210457\n",
      "epoch: 35; loss1023.3600325286388\n",
      "new best model saved\n",
      "epoch: 36; loss1019.1320294439793\n",
      "new best model saved\n",
      "epoch: 37; loss1012.3920290768147\n",
      "epoch: 38; loss1012.6360284686089\n",
      "new best model saved\n",
      "epoch: 39; loss1008.0440280735493\n",
      "epoch: 40; loss1009.9120299518108\n",
      "epoch: 41; loss1009.3080301582813\n",
      "new best model saved\n",
      "epoch: 42; loss998.9400305747986\n",
      "epoch: 43; loss999.4280285537243\n",
      "epoch: 44; loss1001.3080288767815\n",
      "epoch: 45; loss1003.316029459238\n",
      "epoch: 46; loss1001.8840284347534\n",
      "new best model saved\n",
      "epoch: 47; loss993.4000299274921\n",
      "epoch: 48; loss996.3720298409462\n",
      "epoch: 49; loss1001.2680293619633\n"
     ]
    }
   ],
   "source": [
    "functional.reset_net(model)\n",
    "check = input('running this will remove the old saved model')\n",
    "best_loss = 10000000.0\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_samples = 0\n",
    "    for x, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        label_onehot = F.one_hot(label, 10).float()\n",
    "\n",
    "        if scaler is None:\n",
    "            out_fr = 0.\n",
    "            # for t in range(timesteps):\n",
    "            #     encoded_img = encoder(x)\n",
    "            #     out_fr += model(encoded_img)\n",
    "            # out_fr = out_fr / timesteps\n",
    "            loss = F.mse_loss(out_fr, label_onehot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            with amp.autocast():\n",
    "\n",
    "                out_fr = model(x)\n",
    "                # out_fr = out_fr / timesteps\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "        train_samples += label.numel()\n",
    "        train_loss += loss.item() * label.numel()\n",
    "        # print(out_fr.shape)\n",
    "        # print(label.shape)\n",
    "        train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "        functional.reset_net(model) #need to reset the snn before reuse\n",
    "    if train_loss < best_loss:\n",
    "        torch.save(model.state_dict(), f=full_path)\n",
    "        best_loss = train_loss\n",
    "        print('new best model saved')\n",
    "    print('epoch: ' + str(epoch) + '; loss' + str(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = './Models/'\n",
    "full_path = file_dir + '/CSNN.pt'\n",
    "checkpoint = torch.load(f=full_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8835; loss: 185.45600476861\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "test_samples = 0\n",
    "for x, label in test_loader:\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    label = label.to(device)\n",
    "    label_onehot = F.one_hot(label, 10).float()\n",
    "    out_fr = model(x)\n",
    "    loss = F.mse_loss(out_fr, label_onehot)\n",
    "    \n",
    "    test_samples += label.numel()\n",
    "    test_loss += loss.item() * label.numel()\n",
    "    test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "    functional.reset_net(model) #need to reset the snn before reuse\n",
    "test_acc = test_acc/test_samples\n",
    "print('acc: ' + str(test_acc) + '; loss: ' + str(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of Spikes for power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8835; loss: 185.45600681006908\n",
      "SCNN(\n",
      "  (conv_and_fc): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False, step_mode=m)\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)\n",
      "    (2): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)\n",
      "    (4): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1), bias=False, step_mode=m)\n",
      "    (5): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)\n",
      "    (6): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1, step_mode=m)\n",
      "    (9): Linear(in_features=300, out_features=10, bias=False)\n",
      "    (10): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "10000\n",
      "total spikes: 39531208.0\n",
      "timesteps taken: 50000\n"
     ]
    }
   ],
   "source": [
    "spike_monitor = monitor.OutputMonitor(model, neuron.LIFNode)\n",
    "\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "test_samples = 0\n",
    "for x, label in test_loader:\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    label = label.to(device)\n",
    "    label_onehot = F.one_hot(label, 10).float()\n",
    "    out_fr = model(x)\n",
    "    loss = F.mse_loss(out_fr, label_onehot)\n",
    "    \n",
    "    test_samples += label.numel()\n",
    "    test_loss += loss.item() * label.numel()\n",
    "    test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "    functional.reset_net(model) #need to reset the snn before reuse\n",
    "test_acc = test_acc/test_samples\n",
    "print('acc: ' + str(test_acc) + '; loss: ' + str(test_loss))\n",
    "print(model)\n",
    "print(test_samples)\n",
    "total_spikes = 0\n",
    "for tens in spike_monitor.records:\n",
    "    tensnp = tens.cpu().numpy()\n",
    "    total_spikes += np.sum(tensnp) #outputs are just 0's and 1's. summing up will get the total number of spikes of all neurons\n",
    "total_steps = timesteps * test_samples\n",
    "print('total spikes: ' + str(total_spikes))\n",
    "print('timesteps taken: ' + str(total_steps))\n",
    "# print(f'spike_seq_monitor.records=\\n{len(spike_monitor.records)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total power (watts): 616.0739026504\n"
     ]
    }
   ],
   "source": [
    "neurons = 26298\n",
    "Pi = 0.25\n",
    "Pb = 4/1000\n",
    "Pn = 0.0234 #watts (J per second)\n",
    "Ps = 11.3 * (10**-9)\n",
    "\n",
    "power = Pi + Pb + (neurons * Pn) + (total_spikes * Ps)\n",
    "print('total power (watts): ' + str(power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 6, 28, 28])\n",
      "471\n",
      "spike_seq_monitor.monitored_layers=['conv_and_fc.2', 'conv_and_fc.6', 'conv_and_fc.10']\n",
      "torch.Size([6, 1, 5, 5])\n",
      "6\n",
      "torch.Size([6])\n",
      "6\n",
      "torch.Size([6])\n",
      "6\n",
      "torch.Size([12, 6, 5, 5])\n",
      "12\n",
      "torch.Size([12])\n",
      "12\n",
      "torch.Size([12])\n",
      "12\n",
      "torch.Size([10, 300])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(spike_monitor.records[0].shape)\n",
    "print(len(spike_monitor.records))\n",
    "print(f'spike_seq_monitor.monitored_layers={spike_monitor.monitored_layers}')\n",
    "for p in model.parameters():\n",
    "    print(p.shape)\n",
    "    print(len(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
