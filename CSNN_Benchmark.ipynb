{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# spikingjelly.activation_based.examples.conv_fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from spikingjelly.activation_based import encoding, monitor\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from spikingjelly.activation_based import lava_exchange\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from torch.cuda import amp\n",
    "import sys\n",
    "import datetime\n",
    "from spikingjelly import visualizing\n",
    "import numpy as np\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCNN(nn.Module):\n",
    "    def __init__(self, T: int):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.encoder = encoding.PoissonEncoder()\n",
    "        self.conv_and_fc = nn.Sequential(\n",
    "            layer.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2, bias=False),\n",
    "            layer.BatchNorm2d(6),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            layer.Conv2d(in_channels=6, out_channels=12, kernel_size=5, bias=False),\n",
    "            layer.BatchNorm2d(12),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            layer.Flatten(),\n",
    "            layer.Linear(5*5*12, 120, bias=False),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.Linear(120, 84),\n",
    "            neuron.IFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.Linear(84, 10),\n",
    "            neuron.IFNode(surrogate_function=surrogate.ATan())\n",
    "            )\n",
    "        functional.set_step_mode(self, step_mode='m')\n",
    "    def forward(self, x):\n",
    "        original_shape = x.shape\n",
    "        x_rep = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1) #probs between 0 and 1\n",
    "        # print(torch.max(x_rep))\n",
    "        # print(torch.mean(x_rep))\n",
    "        # print(x_rep.shape)\n",
    "        x_seq = self.encoder(x_rep) #use probs to generate random 0's and 1's\n",
    "        # print(x_seq.shape)\n",
    "        z = self.conv_and_fc(x_seq)\n",
    "        fr = z.mean(0)\n",
    "        return fr\n",
    "    # def encode_img(self, img):\n",
    "    #     return self.encoder(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = 2.0\n",
    "timesteps = 10\n",
    "model = SCNN(T=timesteps).to(device=device)\n",
    "EPOCHS=50 #set to 50 epochs bc of diminishing returns\n",
    "AMP=True #automatic mixed precision training\n",
    "lr= 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "out_dir = \"./outputs/CSNN\"\n",
    "encoder = encoding.PoissonEncoder()\n",
    "batch_size=64\n",
    "num_workers = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './FMNIST'\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=train_set,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=test_set,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the CSNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = None\n",
    "if AMP:\n",
    "    scaler = amp.GradScaler()\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    print(f'Mkdir {out_dir}.')\n",
    "\n",
    "writer = SummaryWriter(out_dir, purge_step=0)\n",
    "with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "    args_txt.write('\\n')\n",
    "    args_txt.write(' '.join(sys.argv))\n",
    "file_dir = './Models/'\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)\n",
    "    print(f'Mkdir {file_dir}.')\n",
    "full_path = file_dir + '/CSNN.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best model saved\n",
      "epoch: 0; loss1976.0430250763893\n",
      "new best model saved\n",
      "epoch: 1; loss1326.1370067596436\n",
      "new best model saved\n",
      "epoch: 2; loss1213.9310052394867\n",
      "new best model saved\n",
      "epoch: 3; loss1153.8910070955753\n",
      "new best model saved\n",
      "epoch: 4; loss1103.1390072703362\n",
      "new best model saved\n",
      "epoch: 5; loss1079.2440074384212\n",
      "new best model saved\n",
      "epoch: 6; loss1058.4520105421543\n",
      "new best model saved\n",
      "epoch: 7; loss1031.2150076329708\n",
      "new best model saved\n",
      "epoch: 8; loss1013.7670096158981\n",
      "new best model saved\n",
      "epoch: 9; loss1000.6220080852509\n",
      "new best model saved\n",
      "epoch: 10; loss996.7340102791786\n",
      "new best model saved\n",
      "epoch: 11; loss978.2880076169968\n",
      "new best model saved\n",
      "epoch: 12; loss961.4770079702139\n",
      "new best model saved\n",
      "epoch: 13; loss952.4600071907043\n",
      "new best model saved\n",
      "epoch: 14; loss944.6530073583126\n",
      "new best model saved\n",
      "epoch: 15; loss938.0820101946592\n",
      "new best model saved\n",
      "epoch: 16; loss933.2530103325844\n",
      "new best model saved\n",
      "epoch: 17; loss915.2670090794563\n",
      "new best model saved\n",
      "epoch: 18; loss913.222008138895\n",
      "new best model saved\n",
      "epoch: 19; loss903.0210094600916\n",
      "new best model saved\n",
      "epoch: 20; loss896.3460086882114\n",
      "new best model saved\n",
      "epoch: 21; loss891.6900091767311\n",
      "new best model saved\n",
      "epoch: 22; loss887.7760099172592\n",
      "new best model saved\n",
      "epoch: 23; loss875.6490098387003\n",
      "epoch: 24; loss879.3410097360611\n",
      "new best model saved\n",
      "epoch: 25; loss872.1700081825256\n",
      "epoch: 26; loss875.383009314537\n",
      "new best model saved\n",
      "epoch: 27; loss866.9910088479519\n",
      "new best model saved\n",
      "epoch: 28; loss859.6140077114105\n",
      "new best model saved\n",
      "epoch: 29; loss859.0100063681602\n",
      "new best model saved\n",
      "epoch: 30; loss852.3930114805698\n",
      "new best model saved\n",
      "epoch: 31; loss849.422007009387\n",
      "new best model saved\n",
      "epoch: 32; loss838.994007602334\n",
      "epoch: 33; loss841.152008742094\n",
      "new best model saved\n",
      "epoch: 34; loss834.6600112766027\n",
      "new best model saved\n",
      "epoch: 35; loss833.669006228447\n",
      "new best model saved\n",
      "epoch: 36; loss828.4080081582069\n",
      "new best model saved\n",
      "epoch: 37; loss827.780010163784\n",
      "new best model saved\n",
      "epoch: 38; loss814.4530078917742\n",
      "epoch: 39; loss822.0750104039907\n",
      "new best model saved\n",
      "epoch: 40; loss812.2730100154877\n",
      "epoch: 41; loss819.6580080240965\n",
      "new best model saved\n",
      "epoch: 42; loss807.9740076512098\n",
      "new best model saved\n",
      "epoch: 43; loss801.9730064123869\n",
      "new best model saved\n",
      "epoch: 44; loss801.9070069044828\n",
      "epoch: 45; loss803.9200108647346\n",
      "epoch: 46; loss806.4540110826492\n",
      "new best model saved\n",
      "epoch: 47; loss792.0500058680773\n",
      "new best model saved\n",
      "epoch: 48; loss791.9180086553097\n",
      "epoch: 49; loss794.8770108520985\n"
     ]
    }
   ],
   "source": [
    "functional.reset_net(model)\n",
    "# check = input('running this will remove the old saved model')\n",
    "best_loss = 10000000.0\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_samples = 0\n",
    "    for x, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        label_onehot = F.one_hot(label, 10).float()\n",
    "\n",
    "        if scaler is None:\n",
    "            out_fr = 0.\n",
    "            # for t in range(timesteps):\n",
    "            # encoded_img = encoder(x)\n",
    "            #     out_fr += model(encoded_img)\n",
    "            # out_fr = out_fr / timesteps\n",
    "            out_fr = model(x)\n",
    "            loss = F.mse_loss(out_fr, label_onehot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            with amp.autocast():\n",
    "                # encoded_img = encoder(x)\n",
    "                #encoding inside the model instead\n",
    "                out_fr = model(x)\n",
    "                # out_fr = out_fr / timesteps\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "        train_samples += label.numel()\n",
    "        train_loss += loss.item() * label.numel()\n",
    "        # print(out_fr.shape)\n",
    "        # print(label.shape)\n",
    "        train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "        functional.reset_net(model) #need to reset the snn before reuse\n",
    "    if train_loss < best_loss:\n",
    "        torch.save(model.state_dict(), f=full_path)\n",
    "        best_loss = train_loss\n",
    "        print('new best model saved')\n",
    "    print('epoch: ' + str(epoch) + '; loss' + str(train_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = './Models/'\n",
    "full_path = file_dir + '/CSNN.pt'\n",
    "checkpoint = torch.load(f=full_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8885; loss: 166.0440024882555\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "test_samples = 0\n",
    "for x, label in test_loader:\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    label = label.to(device)\n",
    "    label_onehot = F.one_hot(label, 10).float()\n",
    "    out_fr = model(x)\n",
    "    loss = F.mse_loss(out_fr, label_onehot)\n",
    "    \n",
    "    test_samples += label.numel()\n",
    "    test_loss += loss.item() * label.numel()\n",
    "    test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "    functional.reset_net(model) #need to reset the snn before reuse\n",
    "test_acc = test_acc/test_samples\n",
    "print('acc: ' + str(test_acc) + '; loss: ' + str(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of Spikes for power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8881; loss: 167.79400219768286\n",
      "SCNN(\n",
      "  (encoder): PoissonEncoder()\n",
      "  (conv_and_fc): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False, step_mode=m)\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)\n",
      "    (2): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)\n",
      "    (4): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1), bias=False, step_mode=m)\n",
      "    (5): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)\n",
      "    (6): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1, step_mode=m)\n",
      "    (9): Linear(in_features=300, out_features=120, bias=False)\n",
      "    (10): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (11): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (12): IFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (13): Linear(in_features=84, out_features=10, bias=True)\n",
      "    (14): IFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "10000\n",
      "total spikes: 53161865.0\n",
      "timesteps taken: 100000\n"
     ]
    }
   ],
   "source": [
    "spike_monitor = monitor.OutputMonitor(model, neuron.LIFNode)\n",
    "\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "test_samples = 0\n",
    "for x, label in test_loader:\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    label = label.to(device)\n",
    "    label_onehot = F.one_hot(label, 10).float()\n",
    "    out_fr = model(x)\n",
    "    loss = F.mse_loss(out_fr, label_onehot)\n",
    "    \n",
    "    test_samples += label.numel()\n",
    "    test_loss += loss.item() * label.numel()\n",
    "    test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "    functional.reset_net(model) #need to reset the snn before reuse\n",
    "test_acc = test_acc/test_samples\n",
    "print('acc: ' + str(test_acc) + '; loss: ' + str(test_loss))\n",
    "print(model)\n",
    "print(test_samples)\n",
    "total_spikes = 0\n",
    "for tens in spike_monitor.records:\n",
    "    tensnp = tens.cpu().numpy()\n",
    "    total_spikes += np.sum(tensnp) #outputs are just 0's and 1's. summing up will get the total number of spikes of all neurons\n",
    "total_steps = timesteps * test_samples\n",
    "print('total spikes: ' + str(total_spikes))\n",
    "print('timesteps taken: ' + str(total_steps))\n",
    "# print(f'spike_seq_monitor.records=\\n{len(spike_monitor.records)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total power (watts): 616.2277274147\n"
     ]
    }
   ],
   "source": [
    "neurons = 26298\n",
    "Pi = 0.25\n",
    "Pb = 4/1000\n",
    "Pn = 0.0234 #watts (J per second)\n",
    "Ps = 11.3 * (10**-9)\n",
    "\n",
    "power = Pi + Pb + (neurons * Pn) + (total_spikes * Ps)\n",
    "print('total power (watts): ' + str(power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64, 6, 28, 28])\n",
      "471\n",
      "spike_seq_monitor.monitored_layers=['conv_and_fc.2', 'conv_and_fc.6', 'conv_and_fc.10']\n",
      "torch.Size([6, 1, 5, 5])\n",
      "6\n",
      "torch.Size([6])\n",
      "6\n",
      "torch.Size([6])\n",
      "6\n",
      "torch.Size([12, 6, 5, 5])\n",
      "12\n",
      "torch.Size([12])\n",
      "12\n",
      "torch.Size([12])\n",
      "12\n",
      "torch.Size([120, 300])\n",
      "120\n",
      "torch.Size([84, 120])\n",
      "84\n",
      "torch.Size([84])\n",
      "84\n",
      "torch.Size([10, 84])\n",
      "10\n",
      "torch.Size([10])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(spike_monitor.records[0].shape)\n",
    "print(len(spike_monitor.records))\n",
    "print(f'spike_seq_monitor.monitored_layers={spike_monitor.monitored_layers}')\n",
    "for p in model.parameters():\n",
    "    print(p.shape)\n",
    "    print(len(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
