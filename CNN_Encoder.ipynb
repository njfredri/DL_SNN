{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# spikingjelly.activation_based.examples.conv_fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from spikingjelly.activation_based import encoding, monitor\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from spikingjelly.activation_based import lava_exchange\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from torch.cuda import amp\n",
    "import sys\n",
    "import datetime\n",
    "from spikingjelly import visualizing\n",
    "import numpy as np\n",
    "\n",
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCNN(nn.Module):\n",
    "    def __init__(self, T: int):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv_and_fc = nn.Sequential(\n",
    "            layer.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2, bias=False),\n",
    "            layer.BatchNorm2d(6),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # layer.Conv2d(in_channels=6, out_channels=12, kernel_size=5, bias=False),\n",
    "            # layer.BatchNorm2d(12),\n",
    "            # neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            # layer.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            layer.Flatten(),\n",
    "            layer.Linear(1176, 20, bias=False),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.Linear(20, 10),\n",
    "            neuron.IFNode(surrogate_function=surrogate.ATan())\n",
    "            # layer.Linear(84, 10),\n",
    "            # neuron.IFNode(surrogate_function=surrogate.ATan())\n",
    "            )\n",
    "        functional.set_step_mode(self, step_mode='m')\n",
    "    def forward(self, x):\n",
    "        x_seq = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1)\n",
    "        z = self.conv_and_fc(x_seq)\n",
    "        fr = z.mean(0)\n",
    "        return fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = 2.0\n",
    "timesteps = 10\n",
    "model = SCNN(T=timesteps).to(device=device)\n",
    "EPOCHS=10 #set to 50 epochs bc of diminishing returns\n",
    "AMP=True #automatic mixed precision training\n",
    "lr= 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "out_dir = \"./outputs/CSNN\"\n",
    "encoder = encoding.PoissonEncoder()\n",
    "batch_size=32\n",
    "num_workers = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './FMNIST'\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=train_set,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=test_set,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the CSNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = None\n",
    "if AMP:\n",
    "    scaler = amp.GradScaler()\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    print(f'Mkdir {out_dir}.')\n",
    "\n",
    "writer = SummaryWriter(out_dir, purge_step=0)\n",
    "with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "    args_txt.write('\\n')\n",
    "    args_txt.write(' '.join(sys.argv))\n",
    "file_dir = './Models/'\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)\n",
    "    print(f'Mkdir {file_dir}.')\n",
    "full_path = file_dir + '/CSNN.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best model saved\n",
      "epoch: 0; loss1984.4100384414196\n",
      "new best model saved\n",
      "epoch: 1; loss1569.5520245730877\n",
      "new best model saved\n",
      "epoch: 2; loss1481.535024881363\n",
      "new best model saved\n",
      "epoch: 3; loss1446.0600279420614\n",
      "new best model saved\n",
      "epoch: 4; loss1420.5800228863955\n",
      "new best model saved\n",
      "epoch: 5; loss1390.3170257359743\n",
      "new best model saved\n",
      "epoch: 6; loss1374.5120248645544\n",
      "new best model saved\n",
      "epoch: 7; loss1367.3540232628584\n",
      "new best model saved\n",
      "epoch: 8; loss1356.69602291286\n",
      "new best model saved\n",
      "epoch: 9; loss1337.659019216895\n"
     ]
    }
   ],
   "source": [
    "functional.reset_net(model)\n",
    "# check = input('running this will remove the old saved model')\n",
    "best_loss = 10000000.0\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_samples = 0\n",
    "    for x, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        label_onehot = F.one_hot(label, 10).float()\n",
    "\n",
    "        if scaler is None:\n",
    "            out_fr = 0.\n",
    "            # for t in range(timesteps):\n",
    "            encoded_img = encoder(x)\n",
    "            #     out_fr += model(encoded_img)\n",
    "            # out_fr = out_fr / timesteps\n",
    "            out_fr = model(encoded_img)\n",
    "            loss = F.mse_loss(out_fr, label_onehot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            with amp.autocast():\n",
    "                encoded_img = encoder(x)\n",
    "                out_fr = model(encoded_img)\n",
    "                # out_fr = out_fr / timesteps\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "        train_samples += label.numel()\n",
    "        train_loss += loss.item() * label.numel()\n",
    "        # print(out_fr.shape)\n",
    "        # print(label.shape)\n",
    "        train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "        functional.reset_net(model) #need to reset the snn before reuse\n",
    "    if train_loss < best_loss:\n",
    "        torch.save(model.state_dict(), f=full_path)\n",
    "        best_loss = train_loss\n",
    "        print('new best model saved')\n",
    "    print('epoch: ' + str(epoch) + '; loss' + str(train_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = './Models/'\n",
    "full_path = file_dir + '/CSNN.pt'\n",
    "checkpoint = torch.load(f=full_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8237; loss: 266.1660043299198\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "test_samples = 0\n",
    "for x, label in test_loader:\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    label = label.to(device)\n",
    "    label_onehot = F.one_hot(label, 10).float()\n",
    "    out_fr = model(x)\n",
    "    loss = F.mse_loss(out_fr, label_onehot)\n",
    "    \n",
    "    test_samples += label.numel()\n",
    "    test_loss += loss.item() * label.numel()\n",
    "    test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "    functional.reset_net(model) #need to reset the snn before reuse\n",
    "test_acc = test_acc/test_samples\n",
    "print('acc: ' + str(test_acc) + '; loss: ' + str(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of Spikes for power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8237; loss: 266.1660040616989\n",
      "SCNN(\n",
      "  (conv_and_fc): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False, step_mode=m)\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)\n",
      "    (2): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)\n",
      "    (4): Flatten(start_dim=1, end_dim=-1, step_mode=m)\n",
      "    (5): Linear(in_features=1176, out_features=20, bias=False)\n",
      "    (6): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (7): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (8): IFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "10000\n",
      "total spikes: 29118737.0\n",
      "timesteps taken: 100000\n"
     ]
    }
   ],
   "source": [
    "spike_monitor = monitor.OutputMonitor(model, neuron.LIFNode)\n",
    "\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "test_samples = 0\n",
    "for x, label in test_loader:\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    label = label.to(device)\n",
    "    label_onehot = F.one_hot(label, 10).float()\n",
    "    out_fr = model(x)\n",
    "    loss = F.mse_loss(out_fr, label_onehot)\n",
    "    \n",
    "    test_samples += label.numel()\n",
    "    test_loss += loss.item() * label.numel()\n",
    "    test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "    functional.reset_net(model) #need to reset the snn before reuse\n",
    "test_acc = test_acc/test_samples\n",
    "print('acc: ' + str(test_acc) + '; loss: ' + str(test_loss))\n",
    "print(model)\n",
    "print(test_samples)\n",
    "total_spikes = 0\n",
    "for tens in spike_monitor.records:\n",
    "    tensnp = tens.cpu().numpy()\n",
    "    total_spikes += np.sum(tensnp) #outputs are just 0's and 1's. summing up will get the total number of spikes of all neurons\n",
    "total_steps = timesteps * test_samples\n",
    "print('total spikes: ' + str(total_spikes))\n",
    "print('timesteps taken: ' + str(total_steps))\n",
    "# print(f'spike_seq_monitor.records=\\n{len(spike_monitor.records)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total power (watts): 615.9562417281\n"
     ]
    }
   ],
   "source": [
    "neurons = 26298\n",
    "Pi = 0.25\n",
    "Pb = 4/1000\n",
    "Pn = 0.0234 #watts (J per second)\n",
    "Ps = 11.3 * (10**-9)\n",
    "\n",
    "power = Pi + Pb + (neurons * Pn) + (total_spikes * Ps)\n",
    "print('total power (watts): ' + str(power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 6, 28, 28])\n",
      "626\n",
      "spike_seq_monitor.monitored_layers=['conv_and_fc.2', 'conv_and_fc.6']\n",
      "torch.Size([6, 1, 5, 5])\n",
      "6\n",
      "torch.Size([6])\n",
      "6\n",
      "torch.Size([6])\n",
      "6\n",
      "torch.Size([20, 1176])\n",
      "20\n",
      "torch.Size([10, 20])\n",
      "10\n",
      "torch.Size([10])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(spike_monitor.records[0].shape)\n",
    "print(len(spike_monitor.records))\n",
    "print(f'spike_seq_monitor.monitored_layers={spike_monitor.monitored_layers}')\n",
    "for p in model.parameters():\n",
    "    print(p.shape)\n",
    "    print(len(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
