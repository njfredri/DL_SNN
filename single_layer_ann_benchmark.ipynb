{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version:  2.0.1+cu118\n",
      "GPU availability:  True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import sys\n",
    "\n",
    "print('Pytorch version: ', torch.__version__)\n",
    "print('GPU availability: ', torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='./data'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Single_ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Single_ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) # Flatten every image into a single vector\n",
    "        x = self.fc1(x) #do not use activation function on last layer\n",
    "        return x\n",
    "\n",
    "    def name(self):\n",
    "        return \"MLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 50\n",
    "model = Single_ANN().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, train loss: 0.000348\n",
      "==>>> epoch: 1, train loss: 0.000314\n",
      "==>>> epoch: 2, train loss: 0.000311\n",
      "==>>> epoch: 3, train loss: 0.000310\n",
      "==>>> epoch: 4, train loss: 0.000309\n",
      "==>>> epoch: 5, train loss: 0.000309\n",
      "==>>> epoch: 6, train loss: 0.000310\n",
      "==>>> epoch: 7, train loss: 0.000309\n",
      "==>>> epoch: 8, train loss: 0.000309\n",
      "==>>> epoch: 9, train loss: 0.000309\n",
      "==>>> epoch: 10, train loss: 0.000309\n",
      "==>>> epoch: 11, train loss: 0.000309\n",
      "==>>> epoch: 12, train loss: 0.000309\n",
      "==>>> epoch: 13, train loss: 0.000309\n",
      "==>>> epoch: 14, train loss: 0.000309\n",
      "==>>> epoch: 15, train loss: 0.000309\n",
      "==>>> epoch: 16, train loss: 0.000308\n",
      "==>>> epoch: 17, train loss: 0.000309\n",
      "==>>> epoch: 18, train loss: 0.000309\n",
      "==>>> epoch: 19, train loss: 0.000309\n",
      "==>>> epoch: 20, train loss: 0.000309\n",
      "==>>> epoch: 21, train loss: 0.000309\n",
      "==>>> epoch: 22, train loss: 0.000309\n",
      "==>>> epoch: 23, train loss: 0.000309\n",
      "==>>> epoch: 24, train loss: 0.000309\n",
      "==>>> epoch: 25, train loss: 0.000309\n",
      "==>>> epoch: 26, train loss: 0.000308\n",
      "==>>> epoch: 27, train loss: 0.000308\n",
      "==>>> epoch: 28, train loss: 0.000309\n",
      "==>>> epoch: 29, train loss: 0.000308\n",
      "==>>> epoch: 30, train loss: 0.000309\n",
      "==>>> epoch: 31, train loss: 0.000309\n",
      "==>>> epoch: 32, train loss: 0.000309\n",
      "==>>> epoch: 33, train loss: 0.000308\n",
      "==>>> epoch: 34, train loss: 0.000308\n",
      "==>>> epoch: 35, train loss: 0.000309\n",
      "==>>> epoch: 36, train loss: 0.000309\n",
      "==>>> epoch: 37, train loss: 0.000309\n",
      "==>>> epoch: 38, train loss: 0.000308\n",
      "==>>> epoch: 39, train loss: 0.000309\n",
      "==>>> epoch: 40, train loss: 0.000309\n",
      "==>>> epoch: 41, train loss: 0.000309\n",
      "==>>> epoch: 42, train loss: 0.000309\n",
      "==>>> epoch: 43, train loss: 0.000309\n",
      "==>>> epoch: 44, train loss: 0.000309\n",
      "==>>> epoch: 45, train loss: 0.000309\n",
      "==>>> epoch: 46, train loss: 0.000309\n",
      "==>>> epoch: 47, train loss: 0.000309\n",
      "==>>> epoch: 48, train loss: 0.000309\n",
      "==>>> epoch: 49, train loss: 0.000308\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1000000\n",
    "best_path = './Models/Single_MLP.pt'\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # trainning\n",
    "    total_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, target = x.cuda(), target.cuda()\n",
    "        target_onehot = F.one_hot(target, 10).float()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target_onehot)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    print(f'==>>> epoch: {epoch}, train loss: {avg_loss:.6f}')\n",
    "    # TODO3: Based on average accuracy on validation set, save the model weights into a file\n",
    "    if best_loss > avg_loss:\n",
    "      best_loss = avg_loss\n",
    "      torch.save(model.state_dict(), best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.000312, test accuracy: 0.852800\n"
     ]
    }
   ],
   "source": [
    "best_path = './Models/Single_MLP.pt'\n",
    "checkpoint = torch.load(f=best_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "total_loss = 0\n",
    "correct_cnt = 0\n",
    "model.eval()\n",
    "for batch_idx, (x, target) in enumerate(test_loader):\n",
    "    x, target = x.cuda(), target.cuda()\n",
    "    out = model(x)\n",
    "    target_onehot = F.one_hot(target, 10).float()\n",
    "    loss = criterion(out, target_onehot)\n",
    "\n",
    "    _, pred_label = torch.max(out, 1)\n",
    "    correct_cnt += (pred_label == target).sum()\n",
    "    # smooth average\n",
    "    total_loss += loss.item()\n",
    "avg_loss = total_loss / len(test_dataset)\n",
    "avg_acc = correct_cnt / len(test_dataset)\n",
    "print(f'test loss: {avg_loss:.6f}, test accuracy: {avg_acc:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
